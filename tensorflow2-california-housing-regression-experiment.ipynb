{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2908cccb",
   "metadata": {},
   "source": [
    "# California Housing Regression Model Building\n",
    "\n",
    "This demo shows how you can use SageMaker Studio Notebooks to build machine learning models. We'll cover jupyter extensions, local model building, scaled SageMaker training jobs, Hyperparameter optimnization, and model deployment.\n",
    "\n",
    "Now we will demonstrate these capabilities through a `California Housing` regression example. The experiment will be organized as follows:\n",
    "\n",
    "Make sure you selected `Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f4c39",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installed Libraries\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Project Imports\n",
    "from california_housing_tf2 import get_model, train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55667f49-0f53-4957-940c-31ab59e9eaea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b777f9d",
   "metadata": {},
   "source": [
    "### Download California Housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5905e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(os.getcwd(), \"data/train\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "test_dir = os.path.join(os.getcwd(), \"data/test\")\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "data_set = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b555e84-c1e2-46fa-af6e-ae88dc66a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ac3f4-45aa-4dc7-a7ad-8440f4987ea2",
   "metadata": {},
   "source": [
    "#### Objective\n",
    "The target contains the median of the house value for each district. Therefore, this problem is a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239ce62-dafb-4a96-9033-b5e01993afb4",
   "metadata": {},
   "source": [
    "### Install Plotting Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a468d5-7488-4b5c-bc66-ceede6de9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q plotly nbformat matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1269bb-8109-47f8-bb30-fd733522e427",
   "metadata": {},
   "source": [
    "### Visualize Data with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229e3a2-9d07-4691-b927-6baea0f0c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_set.frame.hist(figsize=(12, 10), bins=15, edgecolor=\"black\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e8af8-9e93-4d25-916e-ac2037519661",
   "metadata": {},
   "source": [
    "### Interactively Visualize Data with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0449f9-a48f-47d5-b413-9930766cfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(data_set.frame[\"HouseAge\"], x=\"HouseAge\", nbins=15)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b551d-342a-42b3-ae34-21b0e3c0a1ea",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24ced8-43e4-4e92-ade8-400e6e0b1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data_set.data, columns=data_set.feature_names)\n",
    "Y = pd.DataFrame(data_set.target)\n",
    "\n",
    "# We partition the dataset into 2/3 training and 1/3 test set.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "np.save(os.path.join(train_dir, \"x_train.npy\"), x_train)\n",
    "np.save(os.path.join(test_dir, \"x_test.npy\"), x_test)\n",
    "np.save(os.path.join(train_dir, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(test_dir, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dbbc89-f1e8-4079-a4b1-3e42255f9547",
   "metadata": {},
   "source": [
    "## Build Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61653951-1e6a-41d6-91c5-1639d00380df",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = get_model()\n",
    "print(my_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a6b1d-a142-4136-961f-02efe7ce697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "train_model(model=my_model, learning_rate=learning_rate, epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            x_train=x_train, y_train=y_train, x_test=x_test,\n",
    "            y_test=y_test, output_dir=os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e3432-9545-4b26-8f75-5130e1f6e137",
   "metadata": {},
   "source": [
    "## Use SageMaker Training Jobs for Scaled Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"tf2-california-housing-experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a63bb-c529-43b9-8a81-f7a60979a6f2",
   "metadata": {},
   "source": [
    "### Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a505630",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_inputs_train = sagemaker.Session().upload_data(\n",
    "    path=\"data/train\", bucket=bucket, key_prefix=prefix + \"/train\"\n",
    ")\n",
    "s3_inputs_test = sagemaker.Session().upload_data(\n",
    "    path=\"data/test\", bucket=bucket, key_prefix=prefix + \"/test\"\n",
    ")\n",
    "inputs = {\"train\": s3_inputs_train, \"test\": s3_inputs_test}\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a989a",
   "metadata": {},
   "source": [
    "### Step 1 - Set up the Experiment\n",
    "\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : [1] a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or [2] a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”), or [3] a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919e497",
   "metadata": {},
   "source": [
    "### Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7609614",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing_experiment = Experiment.create(\n",
    "    experiment_name=f\"tf2-california-housing-{int(time.time())}\",\n",
    "    description=\"Training on california housing dataset\",\n",
    "    sagemaker_boto_client=sm,\n",
    ")\n",
    "print(california_housing_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b261e34a",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment\n",
    "### Now create a Trial for each training run to track its inputs, parameters, and metrics.\n",
    "While training the ResNet-50 CNN model on SageMaker, you will experiment with several values for the number of hidden channel in the model. You will create a Trial to track each training job run. You will also create a `TrialComponent` from the tracker we created before, and add to the Trial. This will enrich the Trial with the parameters we captured from the data pre-processing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_options = {\"learning_rate\": [0.1, 0.5, 0.3], \"epochs\": [100]}\n",
    "\n",
    "hypnames, hypvalues = zip(*hyperparam_options.items())\n",
    "trial_hyperparameter_set = [dict(zip(hypnames, h)) for h in itertools.product(*hypvalues)]\n",
    "trial_hyperparameter_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566ee33",
   "metadata": {},
   "source": [
    "If you want to run the following training jobs asynchronously, you may need to increase your resource limit. Otherwise, you can run them sequentially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "run_number = 1\n",
    "for trial_hyp in trial_hyperparameter_set:\n",
    "    # Combine static hyperparameters and trial specific hyperparameters\n",
    "    hyperparams = trial_hyp\n",
    "\n",
    "    # Create unique job name with hyperparameter and time\n",
    "    time_append = int(time.time())\n",
    "    hyp_append = \"-\".join([str(elm).replace(\".\", \"-\") for elm in trial_hyp.values()])\n",
    "    training_job_name = f\"tf2-california-housing-training-{hyp_append}-{time_append}\"\n",
    "    trial_name = f\"trial-tf2-california-housing-training-{hyp_append}-{time_append}\"\n",
    "    trial_desc = f\"my-tensorflow2-california-housing-run-{run_number}\"\n",
    "\n",
    "    # Create a new Trial and associate Tracker to it\n",
    "    tf2_california_housing_trial = Trial.create(\n",
    "        trial_name=trial_name,\n",
    "        experiment_name=california_housing_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "        tags=[{\"Key\": \"trial-desc\", \"Value\": trial_desc}],\n",
    "    )\n",
    "\n",
    "    # Create an experiment config that associates training job to the Trial\n",
    "    experiment_config = {\n",
    "        \"ExperimentName\": california_housing_experiment.experiment_name,\n",
    "        \"TrialName\": tf2_california_housing_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": training_job_name,\n",
    "    }\n",
    "\n",
    "    metric_definitions = [\n",
    "        {\"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "    ]\n",
    "\n",
    "    # Create a TensorFlow Estimator with the Trial specific hyperparameters\n",
    "    tf2_california_housing_estimator = TensorFlow(\n",
    "        entry_point=\"california_housing_tf2.py\",\n",
    "        role=sagemaker.get_execution_role(),\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        framework_version=\"2.4.1\",\n",
    "        hyperparameters=hyperparams,\n",
    "        py_version=\"py37\",\n",
    "        metric_definitions=metric_definitions,\n",
    "        enable_sagemaker_metrics=True,\n",
    "        tags=[{\"Key\": \"trial-desc\", \"Value\": trial_desc}],\n",
    "    )\n",
    "\n",
    "    # Launch a training job\n",
    "    tf2_california_housing_estimator.fit(\n",
    "        inputs, job_name=training_job_name, experiment_config=experiment_config, wait=False,\n",
    "    )\n",
    "\n",
    "    # give it a while before dispatching the next training job\n",
    "    time.sleep(2)\n",
    "    run_number = run_number + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df253536",
   "metadata": {},
   "source": [
    "### Compare the model training runs for an experiment\n",
    "\n",
    "Now you will use the analytics capabilities of Python SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "experiment_name = california_housing_experiment.experiment_name\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, experiment_name=experiment_name\n",
    ")\n",
    "trial_comp_ds_jobs = trial_component_analytics.dataframe()\n",
    "trial_comp_ds_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4507ae",
   "metadata": {},
   "source": [
    "Let's show the accuracy, epochs and optimizer.\n",
    "You will sort the results by accuracy descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_comp_ds_jobs = trial_comp_ds_jobs.sort_values(\"val_loss - Last\", ascending=False)\n",
    "trial_comp_ds_jobs[[\"TrialComponentName\", \"val_loss - Last\", \"epochs\", \"learning_rate\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb582980",
   "metadata": {},
   "source": [
    "### Compare Experiments, Trials, and Trial Components in Amazon SageMaker Studio\n",
    "\n",
    "You can compare experiments, trials, and trial components by selecting the entities and opening them in the trial components list. The trial components list is referred to as the Studio Leaderboard. In the Leaderboard you can do the following:\n",
    "- View detailed information about the entities\n",
    "- Compare entities\n",
    "- Stop a training job\n",
    "- Deploy a model\n",
    "\n",
    "<b>To compare experiments, trials, and trial components</b>\n",
    "- In the left sidebar of SageMaker Studio, choose the <b>SageMaker Experiment List icon</b>.\n",
    "- In the <b>Experiments</b> browser, choose either the experiment or trial list. \n",
    "- Choose the experiments or trials that you want to compare, right-click the selection, and then choose <b>Open in trial component list</b>. The Leaderboard opens and lists the associated Experiments entities as shown in the following screenshot.\n",
    "\n",
    "![studio_trial_component_list](./images/studio_trial_component_list.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0d456-593a-449b-baa1-3acc4b8e0272",
   "metadata": {},
   "source": [
    "## Use Hyperparamter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be652c-d23d-496e-9d61-9adc92698635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "objective_metric_name = \"loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"val_loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "]\n",
    "\n",
    "hyperparamter_range = {\"learning_rate\": ContinuousParameter(1e-4, 1e-3)}\n",
    "\n",
    "tf2_california_housing_estimator = TensorFlow(\n",
    "    entry_point=\"california_housing_tf2.py\",\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=\"2.4.1\",\n",
    "    py_version=\"py37\",\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    tf2_california_housing_estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparamter_range,\n",
    "    metric_definitions,\n",
    "    base_tuning_job_name=\"housing-hpo\",\n",
    "    strategy=\"Bayesian\",\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=3,\n",
    "    objective_type=objective_type,\n",
    ")\n",
    "\n",
    "tuner.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ddb53-c502-4ec8-9b85-5fd3cef8c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = tuner.\n",
    "results = tuner.analytics()\n",
    "results.training_job_summaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9987d74-8cfc-4119-a52c-6a215a94d3b5",
   "metadata": {},
   "source": [
    "### Deploy Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f826e-0767-4ea8-9a1f-b354fd019962",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = tuner.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c506d4-a9d5-434a-bfff-ecc90fd51926",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(x_test[:10])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae371f8-0569-4ef8-afb8-4dec84eccc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
